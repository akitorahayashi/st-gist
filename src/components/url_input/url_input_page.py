import streamlit as st


def render_url_input_page():
    """Render complete URL input page with header, description, form, and footer"""
    # Removed unused variable 'app_router'

    st.title("ğŸ’ Gist")
    st.write(
        "URLã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãã®ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’åˆ†æãƒ»è¦ç´„ã—ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ãƒšãƒ¼ã‚¸ã«é–¢ã™ã‚‹è³ªå•ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"
    )

    render_url_input_form()


def render_url_input_form():
    """URLå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’æç”»ã—ã€çŠ¶æ…‹ã«åŸºã¥ã„ã¦å‡¦ç†ã‚’åˆ¶å¾¡ã™ã‚‹"""
    app_router = st.session_state.app_router
    scraping_model = st.session_state.scraping_model

    # Load CSS for URL input page styling
    css_files = [
        "src/static/css/base/root.css",
        "src/static/css/url_input_page.css",
        "src/static/css/base/custom-button.css",
    ]

    for css_file in css_files:
        try:
            with open(css_file, "r", encoding="utf-8") as f:
                css_content = f.read()
            st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
        except FileNotFoundError:
            pass  # CSS file not found, continue without styling

    with st.container():
        # URLå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰(å‡¦ç†ä¸­ã¯ç„¡åŠ¹åŒ–)
        target_url = st.session_state.get("target_url", "")
        url_value = (
            target_url
            if scraping_model.is_scraping
            else st.session_state.get("url_input", "")
        )

        st.text_input(
            "URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„" if not scraping_model.is_scraping else "URL",
            placeholder="https://example.com",
            value=url_value,
            key="url_input",
            disabled=scraping_model.is_scraping,
            label_visibility="collapsed",
        )

        if scraping_model.last_error:
            st.error(scraping_model.last_error)
            scraping_model.last_error = None

        st.markdown("<br>", unsafe_allow_html=True)

        def on_summarize_click():
            current_url = st.session_state.get("url_input", "")
            if not current_url.strip():
                scraping_model.last_error = "URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                return
            try:
                scraping_model.validate_url(current_url.strip())
                # session_stateã«ãƒ•ãƒ©ã‚°ã‚’è¨­å®šã—ã¦ã€ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§å‡¦ç†ã•ã›ã‚‹
                st.session_state.should_start_scraping = True
                st.session_state.target_url_to_scrape = current_url.strip()
            except ValueError as e:
                scraping_model.last_error = str(e)

        # ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã¨çŠ¶æ…‹ã‚’å‹•çš„ã«è¨­å®š
        button_text = (
            "ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—ä¸­..." if scraping_model.is_scraping else "è¦ç´„ã‚’é–‹å§‹"
        )
        button_disabled = scraping_model.is_scraping

        st.button(
            button_text,
            use_container_width=True,
            disabled=button_disabled,
            on_click=on_summarize_click if not scraping_model.is_scraping else None,
        )

        # å‡¦ç†ä¸­ã®å ´åˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†
        if scraping_model.is_scraping:
            target_url = st.session_state.get("target_url", "")
            if not target_url:
                scraping_model.is_scraping = False
                scraping_model.last_error = "URLãŒæœªè¨­å®šã§ã™ã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
                st.rerun()
                return
            try:
                scraping_model.scrape(target_url)

                # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†å¾Œã€é·ç§»å‰ã«embeddingã‚’ä½œæˆ
                vector_store = st.session_state.get("vector_store")
                if vector_store and scraping_model.content:
                    vector_store.create_embeddings(scraping_model.content)

                app_router.go_to_chat_page()
                st.rerun()
            except Exception as e:
                scraping_model.is_scraping = False
                scraping_model.last_error = f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
                st.rerun()

        if st.secrets.get("DEBUG"):
            st.info("ç¾åœ¨ã€ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã€MockãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚")

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§ã®ãƒ•ãƒ©ã‚°å‡¦ç†
        if st.session_state.get("should_start_scraping", False):
            # ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€å‡¦ç†ã‚’é–‹å§‹
            st.session_state.should_start_scraping = False
            target_url = st.session_state.get("target_url_to_scrape", "")

            # å‡¦ç†é–‹å§‹
            app_router.set_target_url(target_url)
            scraping_model.is_scraping = True
            st.rerun()  # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§ã®st.rerun()ã¯æœ‰åŠ¹
